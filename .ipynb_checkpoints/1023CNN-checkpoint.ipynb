{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x6527c13c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1234], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1234].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "* 3次conv, 3次max\n",
    "* 2 Dense\n",
    "* output:10 (0-9共10個)\n",
    "\n",
    "filter 大小 3x3 \n",
    "maxpooling 2x2\n",
    "\n",
    "* Conv01: 4 (標準設計法就是2的x次方遞增，但自己想改也可以)\n",
    "* Conv02: 8\n",
    "* Conv03: 16\n",
    "\n",
    "filter 層數要越來越多還是越來越少？Ａ：越來越多（因為一開始是看基本元件，所以不會太多樣）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(4, (5, 5), padding='same', input_shape=(28, 28, 1),\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(8, (5, 5), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (5, 5), padding='same',\n",
    "                activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 dense 標準神經網路層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(17, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=\"categorical_crossentropy\",\n",
    "#              optimizer=Adadelta(),\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.07), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 4)         104       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 8)         808       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 16)          3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 17)                2465      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                180       \n",
      "=================================================================\n",
      "Total params: 6,773\n",
      "Trainable params: 6,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_11_input to have 4 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-46dfa053d248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_11_input to have 4 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
